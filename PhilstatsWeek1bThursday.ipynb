{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "807c384d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Philstats Week 1 Thursday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199bd9d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Outline**\n",
    "\n",
    "[Review of set-theoretic operations](#Review-of-set-theoretic-operations)\n",
    "\n",
    "[Probability axioms](#Probability-axioms)\n",
    "\n",
    "[Conditioning and conditionals](#Conditioning-and-conditionals)\n",
    "\n",
    "[Interpretations of probability](#Interpretations-of-probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8ce0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review of set-theoretic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee8cb84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall from last time:\n",
    "\n",
    "**Set-theoretic operations**\n",
    "\n",
    "We are usually just working with subsets of a given set $\\Omega$, which is fixed by the topic at hand.\n",
    "\n",
    "There's some operations that we need to remind ourselves of:\n",
    "\n",
    "- Intersection of $A,B$, symbol $A\\cap B$, definition: $A\\cap B= \\{x\\in \\Omega: x\\in A \\wedge x\\in B\\}$ \n",
    "\n",
    "- Union of $A,B$, symbol $A\\cup B$, definition: $A\\cup B= \\{x\\in \\Omega: x\\in A \\vee x\\in B\\}$ \n",
    "\n",
    "- Difference of $A$ from $B$, symbol $A\\mbox{-} B$, definition: $A\\mbox{-} B = \\{x\\in \\Omega: x\\in A \\wedge x\\notin B\\}$ \n",
    "\n",
    "- Relative complement of $A$, symbol $A^c$ or $\\overline{A}$, definition: $A^c = \\overline{A} =\\{x\\in \\Omega: x\\notin A\\}$\n",
    "\n",
    "The empty set $\\emptyset$ is the subset of $\\Omega$ that has no elements.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db867266",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition** (subset)\n",
    "\n",
    "A set $A$ is a *subset* of $B$ if every element of $A$ is also an element of $B$.\n",
    "\n",
    "We write $A\\subseteq B$ for $A$ is a subset of $B$. \n",
    "\n",
    "For instance $\\{0,1,2\\}$ is a subset of $\\{0,1,2,3,4\\}$ since each number in the first set is in the second set.\n",
    "\n",
    "But we do not have $\\{0,1,2\\}$ is a subset of $\\{1,2,3,4\\}$ since $0$ is in the first set but not in the second set.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7551da8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition** (disjointness)\n",
    "\n",
    "Sets $A,B$ are *disjoint* if $A\\cap B=\\emptyset$\n",
    "\n",
    "For instance, $\\{1,2,3\\}$ and $\\{8,9,10\\}$ are disjoint.\n",
    "\n",
    "Sets $A,B,C$ are *pairwise disjoint* if $A,B$ are disjoint and $A,C$ are disjoint and $B,C$ are disjoint.\n",
    "\n",
    "For instance, $\\{1,2\\}, \\{8,9\\}, \\{15,16\\}$ are pairwise disjoint.\n",
    "\n",
    "We define pairwise disjointness for longer sequences of sets similarly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ebc0de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Recall** from last time:\n",
    "\n",
    "|  | Philosophy | Probability | Logic | Math |\n",
    "|:----------:|:----------:|:----------:|:----------:|:----------:|\n",
    "|   $\\Omega$  |   Set of worlds  |   Sample space  | Set of models | Underlying set \n",
    "|   $\\{A: A\\subseteq \\Omega\\}$  |   Set of propositions  |   Event space  | Sets determined by formulas | Powerset of underlying set\n",
    "|   $X:\\Omega\\rightarrow \\mathbb{R}$  |  na  |   Random variable  | na | Real-valued function\n",
    "|   $\\{\\omega\\in \\Omega: X(\\omega)\\in R\\}$  |  na  |  the event $X\\in R$  | na | the set $X^{-1}(R)$, called the inverse image\n",
    "\n",
    "In this last one, $R$ is a subset of the reals $\\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911668e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**In what follows, we use the probability terminology.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d45af5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability axioms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89b642",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition** (probability axioms)\n",
    "\n",
    "A *probability measure* $P$ is a function from subsets of the space $\\Omega$ to real numbers  satisfying the following for all events $A,B\\subseteq \\Omega$:\n",
    "\n",
    "- Non-negativity: $P(A)\\geq 0$ \n",
    "\n",
    "- Finite additivity: $P(A\\cup B)=P(A)+P(B)$ if $A\\cap B=\\emptyset$ \n",
    "\n",
    "- Value of entire space: $P(\\Omega)=1$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a267dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again, if $\\Omega$ is infinite, one will in general need to restrict attention to Borel events (or some other reasonably defined class of events). And again, we ignore this issue here, not because it is unimportant but because it is a slightly different subject (measure theory and/or descriptive set theory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88aab81",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For rest of this section, we fix $\\Omega$ and only consider events (sets) which are subsets of $\\Omega$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ddd19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition** (value of complements)\n",
    "\n",
    "For all events $A$, we have: $P(A^c)=1-P(A)$\n",
    "\n",
    "*Proof*: \n",
    "\n",
    "We always have $\\Omega = (\\Omega\\mbox{-}A)\\cup A$ and $\\Omega\\mbox{-}A, A$ are disjoint (Draw the picture)\n",
    "\n",
    "Then by finite additivity one has:\n",
    "\n",
    "$1 = P(\\Omega) = P((\\Omega\\mbox{-}A)\\cup A) = P(\\Omega\\mbox{-}A)+P(A)=P(A^c)+P(A)$\n",
    "\n",
    "Then subtract $P(A)$ from both sides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42981e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Corollary** (value for emptyset)\n",
    "\n",
    "We have $P(\\emptyset)=0$\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "Since $\\emptyset^c =\\Omega$ we have\n",
    "\n",
    "$P(\\emptyset^c) =1-P(\\Omega)=1-1=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07baebc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition** (monotonicity)\n",
    "\n",
    "For all events $A,B$ if $A\\subseteq B$ then $P(A)\\leq P(B)$\n",
    "\n",
    "Proof: \n",
    "\n",
    "When $A\\subseteq B$ we have $B=A\\cup (B\\mbox{-}A)$ and $A,B\\mbox{-}A$ are disjoint. (Draw the picture)\n",
    "\n",
    "We then appeal to finite monotoncity as follows:\n",
    "\n",
    "$P(B) = P(A)+P(B\\mbox{-}A)\\geq P(A)$\n",
    "\n",
    "For the last inequality, we appeal to non-negativity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9adf6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Corollary** (values in the interval 0 to 1)\n",
    "\n",
    "For all events $A$, we have $0\\leq P(A)\\leq 1$.\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "We always have $A\\subseteq \\Omega$. \n",
    "\n",
    "Hence by monotonicity $P(A)\\leq P(\\Omega) =1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a52a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition** (finite additivity, redeux)\n",
    "\n",
    "For pairwise disjoint events $A,B,C$ one has\n",
    "\n",
    "$P(A\\cup B\\cup C) = P(A)+P(B)+P(C)$\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "If $A,B,C$ are pairwise disjoint, then $A, B\\cup C$ are disjoint too (draw the picture). Then by two applications of finite additivity we have\n",
    "\n",
    "$P(A\\cup B \\cup C) = P(A)+P(B\\cup C)=P(A)+P(B)+P(C)$\n",
    "\n",
    "*Note 1*:\n",
    "\n",
    "In this proof, we are relying on rules of sets, such as associativity of union, which says that $(A\\cup B)\\cup C=A\\cup (B\\cup C)$, and so we can \"drop parentheses\" and just write it as $A\\cup B\\cup C$.\n",
    "\n",
    "*Note 2*:\n",
    "\n",
    "The same proposition holds for any finite sequence of pairwise disjoint events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c68861",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Proposition** (inclusion-exclusion)\n",
    "\n",
    "For all events $A,B$ we have \n",
    "\n",
    "$P(A\\cup B) = P(A)+P(B)-P(A\\cap B)$\n",
    "\n",
    "*Proof* (less detailed):\n",
    "\n",
    "$P(A\\cup B) = P(A\\mbox{-}B) + P(B\\mbox{-}A) + P(A\\cap B)$\n",
    "\n",
    "$\\hspace{20mm} = P(A)-P(A\\cap B)+P(B)-P(A\\cap B)+P(A\\cap B)$\n",
    "\n",
    "$\\hspace{20mm} = P(A)+P(B)-P(A\\cap B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886d9db",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Proof* (more detailed):\n",
    "\n",
    "We have that $A\\cup B = (A\\mbox{-}B)\\cup (B\\mbox{-}A) \\cup (A\\cap B)$ and $A\\mbox{-}B, B\\mbox{-}A, A\\cap B$ are  are pairwise disjoint (draw the picture)\n",
    "\n",
    "Hence by finite additivity we have\n",
    "\n",
    "(1) $P(A\\cup B) = P(A\\mbox{-}B) + P(B\\mbox{-}A) + P(A\\cap B)$\n",
    "\n",
    "But we also have $A=(A\\mbox{-}B)\\cup (A\\cap B)$ and $B=(B\\mbox{-}A)\\cup (A\\cap B)$ and the relevant sets are disjoint (draw the picture)\n",
    "\n",
    "Hence by finite additivity and some subtraction we get:\n",
    "\n",
    "(2) $P(A)=P(A\\mbox{-}B)+ P(A\\cap B)$\n",
    "\n",
    "(2') $P(A\\mbox{-}B)=P(A)-P(A\\cap B)$\n",
    "\n",
    "(3) $P(B)=P(B\\mbox{-}A)+P(A\\cap B)$\n",
    "\n",
    "(3') $P(B\\mbox{-}A)=P(B)-P(A\\cap B)$\n",
    "\n",
    "We then just chain together (1), (2'), (3') to get\n",
    "\n",
    "$P(A\\cup B) = P(A\\mbox{-}B) + P(B\\mbox{-}A) + P(A\\cap B)$\n",
    "\n",
    "$\\hspace{20mm} = P(A)-P(A\\cap B)+P(B)-P(A\\cap B)+P(A\\cap B)$\n",
    "\n",
    "$\\hspace{20mm} = P(A)+P(B)-P(A\\cap B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c49c22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditioning and conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d4a64",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition** (Conditional probability)\n",
    "\n",
    "Suppose that $P$ is a probability measure and $P(E)>0$. Then the *conditional probability* $P(H\\mid E)$ of $H$ given $E$ is $$P(H\\mid E)=\\frac{P(H\\cap E)}{P(E)}$$\n",
    "\n",
    "**Alterate notation** (Subscript notation for conditional probability)\n",
    "\n",
    "We also write: $P_E(H)=P(H|E)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b55ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Convention** (Assume your interlocutor is not dividing by zero)\n",
    "\n",
    "Whenever anyone writes $P(H|E)$ or $P_E(H)$, assume that they are restricting their statement to the case where $P(E)>0$. \n",
    "\n",
    "This saves us from needing to write out this hypothesis over and over again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7da42b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition** (repeated conditioning)\n",
    "\n",
    "$P_E(H\\mid E') = P(H\\mid E\\cap E')$\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "$$ P_E(H\\mid E') =\\frac{P_E(H\\cap E')}{P_E(E')} = \\frac{P(H\\cap E'\\cap E)/P(E')}{P(E\\cap E')/P(E')} = \\frac{P(H\\cap E'\\cap E)}{P(E\\cap E')} = P(H\\mid E\\cap E')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841d227",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition** (conditioning induces a probability measure)\n",
    "\n",
    "For all $E$, one has that $P_E$ is also a probability measure.\n",
    "\n",
    "*Proof*: Non-negativity: $P_E(A)=\\frac{P(A\\cap E)}{P(E)}\\geq 0$. \n",
    "\n",
    "Finite additivity: assuming $A,B$ are disjoint, we have \n",
    "\n",
    "$P_E(A)+P_E(B)=\\frac{P(A\\cap E)}{P(E)}+\\frac{P(B\\cap E)}{P(E)}=\\frac{P((A\\cap E)\\cup (B\\cap E))}{P(E)}=\\frac{P((A\\cup B)\\cap E)}{P(E)}=P_E(A\\cup B)$\n",
    "\n",
    "The first identity is definition, the second is $A\\cap E, B\\cap E$ disjoint (draw picture); the third identity is distributivity; the last identity is definition.\n",
    "\n",
    "Value of the whole space: $P_E(\\Omega) = \\frac{P(\\Omega\\cap E)}{P(E)} = \\frac{P(E)}{P(E)}=1$ since $\\Omega\\cap E=\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc82b227",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Theorem** (Bayes' theorem / formula)\n",
    "\n",
    "$$P(H\\mid E) = \\frac{P(E\\mid H)\\cdot P(H)}{P(E)}$$\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "Bayes' formula can be verified by moving from the right-to-left, with the probabilities of the hypotheses cancelling on top and bottom:\n",
    "\n",
    "$$ \\frac{P(E\\mid H)\\cdot P(H)}{P(E)} = \\frac{P(E\\cap H)\\cdot P(H)}{P(H)\\cdot P(E)} = \\frac{P(H\\cap E)}{P(E)} = P(H\\mid E)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba2d3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Definition** (Likelihood, Prior, Posterior)\n",
    "\n",
    "In the context of Bayes' Theorem, one has names for the certain quantities:\n",
    "\n",
    "$$P(H\\mid E) = \\frac{P(E\\mid H)\\cdot P(H)}{P(E)}, \\hspace{20mm} \\mathrm{posterior\\;probability}= \\frac{\\mathrm{likelihood} \\times \\mathrm{prior\\;probability} }{\\mathrm{probability\\;of\\;evidence} } $$\n",
    "\n",
    "In English: the probability of a hypothesis conditional on evidence is equal to the likelihood of the evidence given the hypothesis times the prior probability associated to the hypothesis, divided by the probability associated to the evidence.\n",
    "\n",
    "It is useful in situations where one has some sense already of which hypotheses make the evidence at hand more or less probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd440e54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition**\n",
    "\n",
    "$P(H) = P(H|E)\\cdot P(E)+P(H|E^c)\\cdot P(E^c)$\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "We have $H=(H\\cap E)\\cup (H\\cap E^c)$ and $H\\cap E, H\\cap E^c$ are disjoint. \n",
    "\n",
    "Then $P(H)=P(H\\cap E) +P(H\\cap E^c) = P(H|E)\\cdot P(E)+P(H|E^c)\\cdot P(E^c)$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8065767",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Theorem** (Lewis-Stalnaker trivality)\n",
    "\n",
    "Suppose that conditional probability was *factive*, in that there is a binary operation $\\Rightarrow$ on subsets of $\\Omega$ such that $P(H|E) = P(E\\Rightarrow H)$ for all $P,H,E$ with $P(E)>0$.\n",
    "\n",
    "Then conditional probability is *trivial* in that $P(H|E) = P(H)$ for all $E,H$ with $P(H\\cap E), P(E\\cap H^c)>0$.\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "$P(H|E)=P(E\\Rightarrow H) = P(E\\Rightarrow H\\mid H)\\cdot P(H)+P(E\\Rightarrow H\\mid H^c)\\cdot P(H^c)$\n",
    "\n",
    "$\\hspace{15mm} = P_H(E\\Rightarrow H)\\cdot P(H)+P_{H^c}(E\\Rightarrow H)\\cdot P(H^c)$\n",
    "\n",
    "$\\hspace{15mm} = P_H(H|E)\\cdot P(H)+P_{H^c}(H|E)\\cdot P(H^c)$\n",
    "\n",
    "$\\hspace{15mm} = P(H|E\\cap H)\\cdot P(H)+P(H|E\\cap H^c)\\cdot P(H^c)$ by repeated conditioning\n",
    "\n",
    "$\\hspace{15mm} = 1\\cdot P(H)+0 \\cdot P(H^c)$\n",
    "\n",
    "$\\hspace{15mm} = P(H)$\n",
    "\n",
    "*Note*: next week we will recognize the 'triviality' as a kind of 'too much independence.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c210d47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretations of probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4d5dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Laplace and the principle of indifference**\n",
    "\n",
    "From the *Philosophy Essay on Probabilities* (p. 4):\n",
    "\n",
    ">The theory of chances consists in reducing all events of the same kind to a certain number of equally possible cases, that is to say, to cases whose existence we are equally uncertain of, and in determining the number of cases favourable to the event whose probability is sought. The ratio of this number to that of all possible cases is the measure of this probability, which is thus only a fraction whose numerator is the number of favourable cases, and whose denominator is the number of all possible cases.\n",
    "\n",
    "It seems he is thus interested in what we would call today the *uniform* measure on a finite space. \n",
    "\n",
    "If $\\Omega$ has cardinality $n$ and an event $A$ has $m$ elements, then we define $P(A)=\\frac{m}{n}$.\n",
    "\n",
    "If we use $\\left|\\cdot\\right|$ for cardinality (or size), then this can be written as $P(A)=\\frac{\\left|A\\right|}{\\left|\\Omega\\right|}$.\n",
    "\n",
    "Virtues: connects our epistemic state to the probabilites, and gets simple cases of fair coin flips right. \n",
    "\n",
    "Vices: more often than not, we are not interested in the uniform measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bca013",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**von Mises and frequentism**\n",
    "\n",
    "Given a space $\\Omega$, consider the \"superspace\" $\\Omega^{\\mathbb{N}}=\\{f:\\mathbb{N}\\rightarrow \\Omega\\}$, i.e. the set of all functions from the natural numbers to $\\Omega$. \n",
    "\n",
    "For instance if $\\Omega =\\{0,1\\}$, then $\\Omega^{\\mathbb{N}}$ is *Cantor space*, the space of all infinite sequences of zeros and ones. This is a good initial representation of the space of all infinite sequences of coin flips. \n",
    "\n",
    "Then for such a function $f$, define $P_f(A) = \\lim_n \\frac{\\left|\\{m\\leq n: f(m)\\in A\\}\\right|}{n}$.\n",
    "\n",
    "That is, it is the limiting relative frequency of $A$'s that appear in the sequence $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2031a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Virtues of frequentism**\n",
    "\n",
    "One can derive the elementary laws of probability. \n",
    "\n",
    "For instance, if $A,B$ are disjoint and the relevant limits exist, then\n",
    "\n",
    "$P_f(A\\cup B) = \\lim_n \\frac{\\left|\\{m\\leq n: f(m)\\in A\\cup B \\}\\right|}{n}$.\n",
    "\n",
    "$\\hspace{15mm} = \\lim_n \\frac{\\left|\\{m\\leq n: f(m)\\in A \\}\\right|+\\left|\\{m\\leq n: f(m)\\in B \\}\\right|}{n}$\n",
    "\n",
    "$\\hspace{15mm} = \\lim_n \\frac{\\left|\\{m\\leq n: f(m)\\in A \\}\\right|+\\lim_n \\left|\\{m\\leq n: f(m)\\in B \\}\\right|}{n}$\n",
    "\n",
    "$\\hspace{15mm} = P_f(A)+P_f(B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5181669",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Vices of frequentism**\n",
    "    \n",
    "One has to assume that the limits exist and von Mises postualtes this rather than explains it. Some sequences don't have limits. Imagine a sequence that has long stretches where the frequency is $\\frac{1}{3}$ followed by long stretches where the frequency is $\\frac{2}{3}$, repeated ad nauseum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65a46f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Vices of frequentism, con't**\n",
    "\n",
    "Von Mises postulated that the limiting relative frequency is not changed by passing to subsequences. (See von Mises 1957 pp. 23-25, 28-29, 65).\n",
    "\n",
    "Let $\\Omega =\\{0,1\\}$ i.e. a single flip of tails and heads. Let $\\Omega' = \\{00, 01, 10, 11\\}$, i.e. two flips of heads and tails. Let $g(m)=f(2m)$. \n",
    "\n",
    "Then under the assumption that all the relevant limits exist one has:\n",
    "\n",
    "$P_{g}(\\{1\\}) = \\lim_n \\frac{\\left|\\{m\\leq n: f(2m)=1\\}\\right|}{n}$\n",
    "\n",
    "$\\hspace{15mm} = \\lim_n \\frac{\\left|\\{m\\leq n: f(2m)=1, f(2m+1)=0\\}\\right|}{n}$\n",
    "\n",
    "$\\hspace{20mm} + \\lim_n \\frac{\\left|\\{m\\leq n: f(2m)=1, f(2m+1)=1\\}\\right|}{n}$\n",
    "\n",
    "$\\hspace{15mm} = P'_{f'}(\\{10\\})+ P'_{f'}(\\{11\\})$\n",
    "\n",
    "$\\hspace{15mm} = \\frac{1}{4}+\\frac{1}{4} = \\frac{1}{2}\\hspace{10mm}$  ($\\star$)\n",
    "\n",
    "where $f'(m) = f(2m)f(2m+1)$. \n",
    "\n",
    "The reason for ($\\star$) is philosophical: if $P_f$ succeeded in getting the fair measure on $\\Omega$, then $P'_{f'}$ should suceed in being the fair measure on $\\Omega'$.\n",
    "\n",
    "See Van Lambalgen 1987 pp. 36-37."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af5d87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Subjective Bayesianism**\n",
    "\n",
    "De Finetti described his own view as *subjectivism*, but it is now usually called just *Bayesianism* or perhaps sometimes *subjective Bayesianism*. \n",
    "\n",
    "The basic idea is that probabilities are just degrees of confidence or degrees of belief: they are reflective of the subjective evaluations of agents.\n",
    "\n",
    "Different subjective Bayesians will differ in terms of how they understand the \"reflectiveness\", and can range the gamut from pyschologically real states of agents to the best way to understand from an external point of view the bevahior of an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c5f75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**de Finietti vs. von Mises**\n",
    "\n",
    "Both von Mises and de Finetti were primarily concerned to give a scientifically acceptable account of probability. \n",
    "\n",
    "Von Mises is often counted as a member of the Vienna circle.\n",
    "\n",
    "Similarly, de Finetti speaks of his motivation as stemming from a view that \"Every notion is only a word without meaning so long as it is not known how to verify practically any statement at all where this notion comes up ...\" (De Finetti 1964 p. 148).\n",
    "\n",
    "For von Mises, probability was appropriately scientific because \"the relative frequency of the repetition is the 'measure' of probability, just as the length of a column of mercury is the 'measure' of temperature\" (Von Moses 1957 p. vi).\n",
    "\n",
    "For de Finetti, probability was operationalized in terms of human belief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c0f79",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Virtues of subjective Bayesianism**\n",
    "\n",
    "There are arguments from betting behavior (Dutch books) that one's degrees of belief satisfy the probability axioms, if one acts in an appropriately rational manner.\n",
    "\n",
    "Similarly, in the finite case, there are arguments from accuracy, to the effect that any violations of the laws of probability would make one's credences less close to the truth than they otherwise could be.\n",
    "\n",
    "These are really subjects for another course. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b01b5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Vices of subjective Bayesianism**\n",
    "\n",
    "It is harder to see how one is going to get relative frequences to emerge out of this (if one thought that was a good thing). But Bayesians have some things to say about this (exchangeability)\n",
    "\n",
    "The Bayesian updating procedure has a hard time with the problem of \"old evidence\": namely the problem of how to account for how a theory's ability to explain an old already-updated-upon piece of evidence lends credence to the theory. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
