%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Sean Walsh at 2024-04-12 09:15:42 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@book{Schervish2012-cn,
	abstract = {The aim of this graduate textbook is to provide a comprehensive
               advanced course in the theory of statistics covering those
               topics in estimation, testing, and large sample theory which a
               graduate student might typically need to learn as preparation
               for work on a Ph.D. An important strength of this book is that
               it provides a mathematically rigorous and even-handed account of
               both Classical and Bayesian inference in order to give readers a
               broad perspective. For example, the ``uniformly most powerful''
               approach to testing is contrasted with available
               decision-theoretic approaches.},
	author = {Schervish, Mark J},
	date-added = {2024-04-12 09:15:20 -0700},
	date-modified = {2024-04-12 09:15:25 -0700},
	language = {en},
	month = dec,
	publisher = {Springer},
	title = {Theory of Statistics},
	year = 2012}

@book{Gabbay2011-ll,
	abstract = {Statisticians and philosophers of science have many common
               interests but restricted communication with each other. This
               volume aims to remedy these shortcomings. It provides
               state-of-the-art research in the area of philosophy of
               statistics by encouraging numerous experts to communicate with
               one another without feeling ``restricted by their disciplines or
               thinking ``piecemeal in their treatment of issues. A second goal
               of this book is to present work in the field without bias toward
               any particular statistical paradigm. Broadly speaking, the
               essays in this Handbook are concerned with problems of
               induction, statistics and probability. For centuries,
               foundational problems like induction have been among
               philosophers' favorite topics; recently, however,
               non-philosophers have increasingly taken a keen interest in
               these issues. This volume accordingly contains papers by both
               philosophers and non-philosophers, including scholars from nine
               academic disciplines. Provides a bridge between philosophy and
               current scientific findings Covers theory and applications
               Encourages multi-disciplinary dialogue},
	author = {Gabbay, D M and Thagard, P and Woods, J and Bandyopadhyay, P S and {others}},
	date-added = {2024-04-12 09:15:01 -0700},
	date-modified = {2024-04-12 09:15:01 -0700},
	language = {en},
	month = may,
	publisher = {Elsevier},
	title = {Philosophy of Statistics},
	year = 2011}

@book{DeGroot2011-we,
	author = {DeGroot, Morris H and Schervish, Mark J},
	date-added = {2024-04-12 09:14:57 -0700},
	date-modified = {2024-04-12 09:14:57 -0700},
	edition = 4,
	language = {en},
	month = jan,
	publisher = {Pearson},
	title = {Probability and Statistics (4th Edition)},
	year = 2011}

@book{Williamson2010-dq,
	abstract = {How strongly should you believe the various propositions that
               you can express? That is the key question facing Bayesian
               epistemology. Subjective Bayesians hold that it is largely
               (though not entirely) up to the agent as to which degrees of
               belief to adopt. Objective Bayesians, on the other hand,
               maintain that appropriate degrees of belief are largely (though
               not entirely) determined by the agent's evidence. This book
               states and defends a version of objective Bayesian epistemology.
               According to this version, objective Bayesianism is
               characterized by three norms: · Probability - degrees of belief
               should be probabilities · Calibration - they should be
               calibrated with evidence · Equivocation - they should otherwise
               equivocate between basic outcomes Objective Bayesianism has been
               challenged on a number of different fronts. For example, some
               claim it is poorly motivated, or fails to handle qualitative
               evidence, or yields counter-intuitive degrees of belief after
               updating, or suffers from a failure to learn from experience. It
               has also been accused of being computationally intractable,
               susceptible to paradox, language dependent, and of not being
               objective enough. Especially suitable for graduates or
               researchers in philosophy of science, foundations of statistics
               and artificial intelligence, the book argues that these
               criticisms can be met and that objective Bayesianism is a
               promising theory with an exciting agenda for further research.},
	author = {Williamson, Jon},
	date-added = {2024-04-12 09:13:50 -0700},
	date-modified = {2024-04-12 09:13:50 -0700},
	language = {en},
	month = may,
	publisher = {Oxford University Press},
	title = {In Defence of Objective Bayesianism},
	year = 2010}

@book{Royall2017-gc,
	abstract = {Interpreting statistical data as evidence, Statistical
                 Evidence: A Likelihood Paradigm focuses on the law of
                 likelihood, fundamental to solving many of the problems
                 associated with interpreting data in this way. Statistics has
                 long neglected this principle, resulting in a seriously
                 defective methodology. This book redresses the balance,
                 explaining why science has clung to a defective methodology
                 despite its well-known defects. After examining the strengths
                 and weaknesses of the work of Neyman and Pearson and the
                 Fisher paradigm, the author proposes an alternative paradigm
                 which provides, in the law of likelihood, the explicit concept
                 of evidence missing from the other paradigms. At the same
                 time, this new paradigm retains the elements of objective
                 measurement and control of the frequency of misleading
                 results, features which made the old paradigms so important to
                 science. The likelihood paradigm leads to statistical methods
                 that have a compelling rationale and an elegant simplicity, no
                 longer forcing the reader to choose between frequentist and
                 Bayesian statistics.},
	author = {Royall, Richard},
	date-added = {2024-04-12 09:13:42 -0700},
	date-modified = {2024-04-12 09:13:42 -0700},
	language = {en},
	month = nov,
	original_id = {d69aa4c7-3667-0446-abb7-ac101969e597},
	publisher = {Routledge},
	title = {Statistical Evidence: A Likelihood Paradigm},
	year = 2017}

@incollection{Sprenger2016-xc,
	abstract = {Abstract. Bayesianism and frequentism are the two grand schools
               of statistical inference, divided by fundamentally different
               philosophical assumptions and},
	author = {Sprenger, Jan},
	booktitle = {The Oxford Handbook of Probability and Philosophy},
	date-added = {2024-04-12 09:13:31 -0700},
	date-modified = {2024-04-12 09:13:31 -0700},
	pages = {382--405},
	title = {Bayesianism vs. Frequentism in Statistical Inference},
	year = 2016}

@article{Sprenger2011-si,
	abstract = {Scientific and statistical inferences build heavily on explicit,
              parametric models, and often with good reasons. However, the
              limited scope of parametric models and the increasing complexity
              of the studied systems in modern science raise the risk of model
              misspecification. Therefore, I examine alternative, data-based
              inference techniques, such as bootstrap resampling. I argue that
              their neglect in the philosophical literature is unjustified:
              they suit some contexts of inquiry much better and use a more
              direct approach to scientific inference. Moreover, they make more
              parsimonious assumptions and often replace theoretical
              understanding and knowledge about mechanisms by careful
              experimental design. Thus, it is worthwhile to study in detail
              how nonparametric models serve as inferential engines in science.},
	author = {Sprenger, Jan},
	date-added = {2024-04-12 09:13:20 -0700},
	date-modified = {2024-04-12 09:13:20 -0700},
	journal = {Synthese},
	month = may,
	number = 1,
	pages = {65--76},
	title = {Science without (parametric) models: the case of bootstrap resampling},
	volume = 180,
	year = 2011}

@book{Sober2015-of,
	abstract = {Ockham's razor, the principle of parsimony, states that simpler
               theories are better than theories that are more complex. It has
               a history dating back to Aristotle and it plays an important
               role in current physics, biology, and psychology. The razor also
               gets used outside of science - in everyday life and in
               philosophy. This book evaluates the principle and discusses its
               many applications. Fascinating examples from different domains
               provide a rich basis for contemplating the principle's promises
               and perils. It is obvious that simpler theories are beautiful
               and easy to understand; the hard problem is to figure out why
               the simplicity of a theory should be relevant to saying what the
               world is like. In this book, the ABCs of probability theory are
               succinctly developed and put to work to describe two 'parsimony
               paradigms' within which this problem can be solved.},
	author = {Sober, Elliott},
	date-added = {2024-04-12 09:13:10 -0700},
	date-modified = {2024-04-12 09:13:10 -0700},
	language = {en},
	month = jul,
	publisher = {Cambridge University Press},
	title = {Ockham's Razors},
	year = 2015}

@book{Savage1972-zh,
	abstract = {Classic analysis of the foundations of statistics and
               development of personal probability, one of the greatest
               controversies in modern statistical thought. Revised edition.
               Calculus, probability, statistics, and Boolean algebra are
               recommended.},
	author = {Savage, Leonard J},
	date-added = {2024-04-12 09:12:58 -0700},
	date-modified = {2024-04-12 09:12:58 -0700},
	language = {en},
	publisher = {Dover},
	title = {The Foundations of Statistics},
	year = 1972}

@book{Mayo1996-re,
	abstract = {We may learn from our mistakes, but Deborah Mayo argues that,
                 where experimental knowledge is concerned, we haven't begun to
                 learn enough. Error and the Growth of Experimental Knowledge
                 launches a vigorous critique of the subjective Bayesian view
                 of statistical inference, and proposes Mayo's own
                 error-statistical approach as a more robust framework for the
                 epistemology of experiment. Mayo genuinely addresses the needs
                 of researchers who work with statistical analysis, and
                 simultaneously engages the basic philosophical problems of
                 objectivity and rationality. Mayo has long argued for an
                 account of learning from error that goes far beyond detecting
                 logical inconsistencies. In this book, she presents her
                 complete program for how we learn about the world by being
                 ``shrewd inquisitors of error, white gloves off.'' Her tough,
                 practical approach will be important to philosophers,
                 historians, and sociologists of science, and will be welcomed
                 by researchers in the physical, biological, and social
                 sciences whose work depends upon statistical analysis.},
	author = {Mayo, Deborah G},
	date-added = {2024-04-12 09:12:49 -0700},
	date-modified = {2024-04-12 09:12:49 -0700},
	language = {en},
	month = aug,
	original_id = {bd9c645b-7342-05c5-b19d-f19761ce76a1},
	publisher = {University of Chicago Press},
	title = {Error and the Growth of Experimental Knowledge},
	year = 1996}

@book{Howson2006-oy,
	abstract = {In this clearly reasoned defense of Bayes's Theorem -- that
               probability can be used to reasonably justify scientific
               theories -- Colin Howson and Peter Urbach examine the way in
               which scientists appeal to probability arguments, and
               demonstrate that the classical approach to statistical inference
               is full of flaws. Arguing the case for the Bayesian method with
               little more than basic algebra, the authors show that it avoids
               the difficulties of the classical system. The book also refutes
               the major criticisms leveled against Bayesian logic, especially
               that it is too subjective. This newly updated edition of this
               classic textbook is also suitable for college courses.},
	author = {Howson, Colin and Urbach, Peter},
	date-added = {2024-04-12 09:12:39 -0700},
	date-modified = {2024-04-12 09:12:39 -0700},
	language = {en},
	publisher = {Open Court Publishing},
	title = {Scientific Reasoning: The Bayesian Approach},
	year = 2006}

@incollection{Hitchcock2009-yj,
	author = {Hitchcock, Christopher},
	booktitle = {The Oxford Handbook of Causation},
	date-added = {2024-04-12 09:12:28 -0700},
	date-modified = {2024-04-12 09:12:28 -0700},
	pages = {299--314},
	title = {Causal Modelling},
	year = 2009}

@article{Hitchcock2001-fv,
	abstract = {WA Te live in exciting times. By'we'I mean philosophers
               study-ing the nature of causation. The past decade or so has
               witnessed a flurry of philosophical activity aimed at crack-ing
               this {\ldots}},
	author = {Hitchcock, Christopher},
	date-added = {2024-04-12 09:12:28 -0700},
	date-modified = {2024-04-12 09:12:28 -0700},
	journal = {J. Philos.},
	number = 6,
	pages = {273--299},
	publisher = {Journal of Philosophy, Inc.},
	title = {The Intransitivity of Causation Revealed in Equations and Graphs},
	volume = 98,
	year = 2001}

@article{Johnson2016-xr,
	abstract = {AbstractFamously, scientific theories are underdetermined by
               their evidence. This occurs in the factor analytic model (FA),
               which is often used to connect concrete data (e.g. test scores)
               to hypothetical notions (e.g. intelligence). After introducing
               FA, three general topics are addressed. (i) Underdetermination:
               the precise reasons why FA is underdetermined illuminates
               various claims about underdetermination, abduction, and
               theoretical terms. (ii) Uncertainties: FA helps distinguish at
               least four kinds of uncertainties. The prevailing practice,
               often encoded in statistical software, is to ignore the most
               difficult kinds, which are essential to FA's underdetermination.
               (iii) What to do: some suggestions for dealing with these
               hardest types of uncertainty are offered.},
	author = {Johnson, Kent},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	date-added = {2024-04-12 09:12:14 -0700},
	date-modified = {2024-04-12 09:12:14 -0700},
	journal = {Nous},
	language = {en},
	month = jun,
	number = 2,
	pages = {329--355},
	publisher = {Wiley},
	title = {Realism and uncertainty of unobservable common causes in factor analysis},
	volume = 50,
	year = 2016}

@book{Jeffreys1948-vt,
	author = {Jeffreys, Harold},
	date-added = {2024-04-12 09:11:58 -0700},
	date-modified = {2024-04-12 09:11:58 -0700},
	language = {en},
	publisher = {Oxford},
	title = {The Theory of Probability},
	year = 1948}

@incollection{Galavotti2014-th,
	author = {Galavotti, Maria Carla},
	booktitle = {The Routledge Companion to Philosophy of Science},
	date-added = {2024-04-12 09:11:46 -0700},
	date-modified = {2024-04-12 09:11:46 -0700},
	edition = {second},
	editor = {Curd, Martin and Psillos, Stathis},
	pages = {458--468},
	title = {Probability},
	year = 2014}

@book{Fisher1990-dp,
	author = {Fisher, Ronald A},
	date-added = {2024-04-12 09:11:34 -0700},
	date-modified = {2024-04-12 09:11:34 -0700},
	publisher = {Oxford University Press},
	title = {Statistical Methods, Experimental Design, and Scientific Inference},
	year = 1990}

@article{Efron1977-vq,
	abstract = {{\ldots} In traditional statistical theory it can be proved that no
               other estimation rule is {\ldots} The paradoxical element in Stein's re
               sult is that it sometimes contradicts this elementary law of
               statistical {\ldots}},
	author = {Efron, Bradley and Morris, Carl},
	date-added = {2024-04-12 09:10:54 -0700},
	date-modified = {2024-04-12 09:10:54 -0700},
	journal = {Sci. Am.},
	number = 5,
	pages = {119--127},
	publisher = {Scientific American, a division of Nature America, Inc.},
	title = {Stein's Paradox in Statistics},
	volume = 236,
	year = 1977}
