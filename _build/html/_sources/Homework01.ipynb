{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "This is due Wednesday April 24 by 11:59pm, for full credit. It can be turned in Thursday April 25 by 11:59pm for a 10% reduction. \n",
    "\n",
    "You can work with 1-2 other students on it, you just have to indicate who else you worked with, and everyone has to write their own solutions.\n",
    "\n",
    "This homework is designed to be a review of Weeks 1-2 of the course (Chapter 1-4 of the book).\n",
    "\n",
    "You submit **via gradescope on bruinlearn**: you do not turn in anything on this page. \n",
    "\n",
    "In terms of workflow, I would recommend:\n",
    "\n",
    "- write it out by hand: everything is short and you should be able to write it out by hand easily\n",
    "\n",
    "- you do not need to repeat the question, just put down your answer\n",
    "\n",
    "- after you done with it, scan it or take photos of it to put into gradescope in bruinlearn\n",
    "\n",
    "- be working near a computer or phone so you can use the links on this page, which reference back to the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "This problem concerns sets and is like [the example of the set theoretic operations](https://logic-teaching.github.io/philstatsbook/Chap01.html#example-of-set-theoretic-operations).\n",
    "\n",
    "Suppose that $\\Omega = \\{0,1,2,3,4,5,6,7,8,9\\}$\n",
    "\n",
    "Let $A = \\{1,5,8\\}$ and let $B$ be the even numbers in $\\Omega$, and let $C$ be the odd numbers in $\\Omega$. \n",
    "\n",
    "List out the elements of each of the following sets. In each case, your answer just consists of a list of numbers, and there is no further work that you need to show.\n",
    "\n",
    "1. $B$\n",
    "\n",
    "2. $C$\n",
    "\n",
    "3. $A\\cap B$\n",
    "\n",
    "4. $A\\cap C$\n",
    "\n",
    "5. $B\\cap C$\n",
    "\n",
    "6. $\\Omega -A$\n",
    "\n",
    "7. $B-A$\n",
    "\n",
    "8. $A-B$\n",
    "\n",
    "9. $A\\cup (B-A)$\n",
    "\n",
    "10. $(A\\cap B)-(A\\cap C)$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "This problem concerns [random variables](https://logic-teaching.github.io/philstatsbook/Chap01.html#random-variables). In [Chapter 4](https://logic-teaching.github.io/philstatsbook/Chap04.html) we found the expectation and variance of various random variables. For the moment, I want to dwell on more elementary aspect of random variables, namely the way in which they generate sets of worlds, which recall are propositions in one part of the philosophical tradition, and which are called events in probability theory. \n",
    "\n",
    "Let $\\Omega = \\{0,1,2\\}$ and $\\Theta = \\{0,1\\}$.Consider the sample space $\\Omega\\times \\Theta$, as in our discussion of [products](https://logic-teaching.github.io/philstatsbook/Chap01.html#products-of-sets). \n",
    "\n",
    "This problem has two parts. \n",
    "\n",
    "First, write out all 6 elements of the product space $\\Omega \\times \\Theta$. \n",
    "\n",
    "Second, consider the random variable $X:\\Omega\\times \\Theta\\rightarrow \\mathbb{R}$ given by $X(\\omega, \\theta)=\\omega$ and the random variable $Y:\\Omega \\times \\Theta \\rightarrow \\mathbb{R}$ given by $Y(\\omega, \\theta)=\\theta$. \n",
    "\n",
    "Write out the elements of each of the following five events:\n",
    "\n",
    "$X=0$, i.e. the set of worlds in the product space which take value 0 under random variable $X$.\n",
    "\n",
    "$X=1$, i.e. the set of worlds in the product space which take value 1 under random variable $X$.\n",
    "\n",
    "$X=2$, i.e. the set of worlds in the product space which take value 2 under random variable $X$.\n",
    "\n",
    "$Y=0$, i.e. the set of worlds in the product space which take value 0 under random variable $Y$.\n",
    "\n",
    "$Y=1$, i.e. the set of worlds in the product space which take value 1 under random variable $Y$.\n",
    "\n",
    "You will see that the events associated to $X$ parition the product space, but in a different way than the events associated to $Y$ partition the product space. \n",
    "\n",
    "This is a general important basic fact about random variables: they induce different partitionings of the sample space (in the finite case; in the infinite case there is a more complicated truth, namely that they induce different $\\sigma$-algebras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "The notion of proposition as \"set of worlds\" goes deep in analytic philosophy. \n",
    "\n",
    "Recall the beginning of [Wittgenstein's Tractatus](https://people.umass.edu/klement/tlp/tlp.pdf#page=12):\n",
    "\n",
    "> The world is all that is the case. [$\\P$] The world is the totality of facts, not of things ({cite}`Wittgenstein1922-ed` $\\S\\S$ 1,1.1)\n",
    "\n",
    "This corresponds to the elementary truth that for all $\\omega$ in a finite sample space $\\Omega$, if one enumerates the subsets $A_1, A_2, \\ldots$ of $\\Omega$ which contain $\\omega$, one has that $\\{\\omega\\}=A_1\\cap A_2 \\cap \\cdots$.\n",
    "\n",
    "Take further Stalnaker's famous saying at the outset of *Inquiry*:\n",
    "\n",
    "> Propositions, the picture suggests, are simply ways of distinguishing between the elements of the relevant range of alternative possibilities- ways that are useful for characterizing and expressing an agent's attitude towards those possibilities. To *understand* a proposition- to the know content of a statement or thought- is to have the capacity to divide the relevant alternatives in right way. To *entertain* a proposition is to focus one's attention on certain possibilities, contrasting them with others. To *distinguish* two propositions is to conceive of a possible situation in which one is true and the other false ({cite}`Stalnaker1987-fw` pp. 4-5)\n",
    "\n",
    "One way of viewing both Wittegenstein and Stalnaker is to suggest that the \"coarse-grained\" notion of proposition can help us understand otherwise philosophically problematic notions: the world can be understood just as the conjunction or intersection of all the true propositions, and propositional attitudes of understanding, entertaining, and distinguishing are not mysterious since having an attitude towards what side of a divide in \"logical space\" you are on is no more problematic than having an attitude towards what side of the street one is on.\n",
    "\n",
    "But largely as matter of sociological accident, philosophers have not asked similar questions about random variables. \n",
    "\n",
    "Do your best, in 2-3 complete English sentences, to do the analogue of either Wittgenstein or Stalnaker but for random variables. Namely identify some phenomena which might otherwise be philosophically mysterious, and try to say how it could be made more intelligible by recourse to some interpretation of random variables.\n",
    "\n",
    "This will be a little rough, and we are not asking for perfection here- rather we are just looking for a good faith effort to engage in the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Per the discussion in [conditioning and conditionals](https://logic-teaching.github.io/philstatsbook/Chap02.html#conditioning-and-conditionals), we need to get used to the idea that there is another notion of \"if . . . then . . .\" in play in probabilistic and statistical settings. This exercise is designed to help us. \n",
    "\n",
    "Suppose $\\Omega$ is a finite sample space and $H,E$ are subsets of $\\Omega$, and $\\omega$ is the world of evaluation and $\\frac{1}{2}\\leq \\epsilon<1$. Here are three notions of conditional:\n",
    "\n",
    "- Strict conditional interpretation: \"if $E$ then $H$\" is true at $\\omega$ if $E\\subseteq H$.\n",
    "\n",
    "- Material conditional interpretation: \"if $E$ then $H$\" is true at $\\omega$ if $\\omega \\in E^c \\cup H$.\n",
    "\n",
    "- Conditional probability interpretation: \"if $E$ then $H$\" is true at $\\omega$ if $P(H|E)>\\epsilon$.\n",
    "\n",
    "Fill out the following table, by putting a $\\checkmark$ if the notion on row header entails the notion on the column header, and a $\\times$ if not. Note that the rows headers are the ones arranged vertically on the left, and the column headers are the ones arranged horizontally on the top. \n",
    "\n",
    "|                   | Strict Conditional | Material Conditional | Conditional Probability |\n",
    "|-------------------|:------------------:|:--------------------:|:----------------------:|\n",
    "| Strict Conditional|        ✔️          |                      |                        |\n",
    "| Material Conditional|                  |         ✔️           |                        |\n",
    "| Conditional Probability|               |                      |           ✔️            |\n",
    "\n",
    "We have filled out the diagonal with $\\checkmark$ since trivially each notion entails iteslf. \n",
    "\n",
    "For full credit, give a brief proof or counterexample for each of your six answers. For the counterexamples, specify the parameters $\\Omega, \\omega, E,H, P, \\epsilon$ (hint: make $\\Omega$ small). For partial credit, just fill in the table correctly.\n",
    "\n",
    "*Note 1*: usually the strict conditional is defined in terms of the modal formula $\\Box(E\\rightarrow H)$. But if the accessibilitiy relation is universal (i.e. each world sees every other world and itself), this just comes down to \"All the $E$ worlds are $H$ worlds.\"\n",
    "\n",
    "*Note 2*: usually the material conditoinal is just defined as $E\\rightarrow H$, and is equivalent to $\\neg E \\vee H$. The above definition makes this relative to the world of evaluation $\\omega$, which one can think of as a row of a truth-table.\n",
    "\n",
    "*Note 3*: there is a vast literature on whether the conditional probability interpretation can help us understand indicative conditionals. See [the SEP entry](https://plato.stanford.edu/entries/conditionals/#ConBelConPro). We might return to that at some point, but the more proximate reason I need us to understand this is that it comes up all the time when reading and thinking about conditional probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "This problem pertains to [Bayes' Theorem](https://logic-teaching.github.io/philstatsbook/Chap02.html#definition-likelihood-prior-posterior). \n",
    "\n",
    "First, a remark, you need to memorize it, with the locutions of posterior probability, likelihood, prior probability, and probability of evidence. It comes up everywhere, even in places where you think it will not.\n",
    "\n",
    "Second, this problem is designed to make sure that you take a moment and understand its operational significance.\n",
    "\n",
    "1. Does increasing the prior probability increase or decrease the posterior probability? Give a simple real-life example of which makes it vivid for you.\n",
    "\n",
    "2. Does increasing the likelihood increase or decrease the posterior probability? Give a simple real-life example of which makes it vivid for you. (and keep in mind when dealing with likelihood the conditional probability interpretation of \"if . . .  then . . . \" statements).\n",
    "\n",
    "3. Does increasing the probability of evidence increase or decrease the posterior probability? Give a simple real-life example of which makes it vivid for you.\n",
    "\n",
    "The real-life example can be described in a single English sentence. \n",
    "\n",
    "Keep in mind that when thinking about Bayes' theorem in this way, one is usually tacitly adopting a [subjective Bayesian perspective](https://logic-teaching.github.io/philstatsbook/Chap02.html#subjective-bayesianism) on the interpretation of probability, on which $P$ is reflective of your degrees of belief and $P_E$ is reflective of degrees of belief after updating on evidence $E$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "In [Chapter 3](https://logic-teaching.github.io/philstatsbook/Chap03.html#) and in [Chapter 4](https://logic-teaching.github.io/philstatsbook/Chap04.html) we went over a number of distributions. For each of the following, say which distribution seems more appropriate: [binomial](https://logic-teaching.github.io/philstatsbook/Chap03.html#binomial), [normal](https://logic-teaching.github.io/philstatsbook/Chap04.html#normal-distribution), [Poisson](https://logic-teaching.github.io/philstatsbook/Chap03.html#poisson), or power law (an example of which is the [Praeto distribution](https://logic-teaching.github.io/philstatsbook/Chap04.html#pareto-distribution)):\n",
    "\n",
    "1. The number of people in a fixed population who have a given blood type\n",
    "\n",
    "2. The height of patients in a large population\n",
    "\n",
    "3. The number of insurance claims made in a given year\n",
    "\n",
    "4. The file-sizes of documents on a computer\n",
    "\n",
    "5. The number of people infected with influenza in a given season\n",
    "\n",
    "6. The frequency with which words occur in a text \n",
    "\n",
    "7. The number of times you will win a lottery if you play it a fixed number of times \n",
    "\n",
    "8. Earnings per share of given stock over a 30-year period\n",
    "\n",
    "You don't have to justify your answers, just say in each case whether binomial, normal, poisson, or power law is more appropriate. \n",
    "\n",
    "*Hint*: think about what kinds of values they each take (e.g. random variables with distribution Binom(n,p) take values in 0, ..., n, while poisson takes values in 0,1,2,...; and normal and power law take real numbers values; in this case, then think about whether it should be bell shaped or should have a heavy tail). \n",
    "\n",
    "*Note*: There are obviously a whole host of different probability distributions, but we just need to have a rough and ready sense of a few contrasts between the basic ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "We mentioned that [expectation is average in the uniform case](https://logic-teaching.github.io/philstatsbook/Chap03.html#example-moral-expectation-is-generalization-of-average).\n",
    "\n",
    "Find a finite sample space $\\Omega=\\{\\omega_1, \\ldots, \\omega_n\\}$ with $n\\geq 3$ and a probability measure $P$ and a random variable $X$ such that $\\mathbb{E}X$ is not equal to the average $\\frac{X(\\omega_1)+\\cdots+X(\\omega_n)}{n}$\n",
    "\n",
    "*Hint*: make $n\\geq 3$ very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "Often the probability of interest is $P(c< X\\leq d)$ for numbers $c<d$. \n",
    "\n",
    "This problem has two parts. \n",
    "\n",
    "First, use finite additivity (or [inclusion-exclusion](https://logic-teaching.github.io/philstatsbook/Chap02.html#proposition-inclusion-exclusion)) to show that \n",
    "\n",
    "$P(c< X\\leq d) = F_X(d)-F_X(c)$\n",
    "\n",
    "*Hint*: this is really just \"definition chasing\" with the [cdf $F_X$ of $X$](https://logic-teaching.github.io/philstatsbook/Chap03.html#definition-cdfs). The proof should be 2 lines long, approximately. \n",
    "\n",
    "Second, go to [Chapter 4](https://logic-teaching.github.io/philstatsbook/Chap04.html#), click the <i class=\"fa fa-rocket\" aria-hidden=\"true\"></i> icon (which says 'Binder' when you move over it) at the top of the page, find the section \"Computing the normal distribution\" and for $X\\sim N(2,2)$, find $P(-0.82<X\\leq 4.82)$ by:\n",
    "\n",
    "```\n",
    "mu = 2 \n",
    "var = 2\n",
    "c = -0.82\n",
    "d = 4.82\n",
    "```\n",
    "\n",
    "Just paste these into the box called \"## computing X ~ Norm(mu,var)\", then press shift + return, and click on box below and press shift + return\n",
    "\n",
    "*Note 1*: this worked better for me on Firebox and Chrome than on Safari. If this doesn't work for you on one browser, then try it on another browser \n",
    "\n",
    "*Note 2*: this illustrates the point (made in {cite}`Tijms2012-ot` p. 146) that \"approximately 95% is concentrated between $\\mu-2\\sigma$ and $\\mu+2\\sigma$\n",
    "\n",
    "*Note 3*: hopefully the comparative ease of this illustrates that it is really easy to use out-of-the-box computational tools to look at concrete examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9\n",
    "\n",
    "Much of what we will do later in this course concerns infinite sequences of independent random variables $X_1, X_2, X_3, \\ldots$ where these represent taking a given measurement (e.g. height) of a long list of samples (e.g. people).\n",
    "\n",
    "But I think that it is still safe to say that this notion occurs rarely in philosophy outside of philosophy of statistics. \n",
    "\n",
    "But many philosophers are sympathetic to certain strains of [subjective Bayesianism](https://logic-teaching.github.io/philstatsbook/Chap02.html#subjective-bayesianism) and think that when we are gathering evidence $E_1, E_2, \\ldots$ we are [conditioning](https://logic-teaching.github.io/philstatsbook/Chap02.html#conditioning-and-conditionals) and updating our degrees of beliefs to $P_{E_1}, P_{E_1\\cap E_2}, P_{E_1\\cap E_2\\cap E_3}, \\ldots$. \n",
    "\n",
    "Use [this proposition](https://logic-teaching.github.io/philstatsbook/Chap04.html#proposition-when-evidence-and-hypothesis-independent-the-posterior-and-prior-are-same) to try to write a 3-4 sentence English explanation- for such a philosopher- of what it means to be working with an infinite sequences of independent random variables $X_1, X_2, X_3, \\ldots$. What does independence mean for their updating process, or for their conditional beliefs? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10\n",
    "\n",
    "Suppose that $X$ has expectation $5$ and variance $3$, and suppose that $Y$ has expectation $-2$ and variance $4$.\n",
    "\n",
    "Let $Z=2\\cdot X-3\\cdot Y+7$. Suppose that $2\\cdot X$ and $-(3\\cdot Y+7)$ are independent (which follows, it turns out, from the independence of $X,Y$)\n",
    "\n",
    "Use the [rules for expectation](https://logic-teaching.github.io/philstatsbook/Chap04.html#proposition-rules-for-expectation) and the rules for variance ([this one](https://logic-teaching.github.io/philstatsbook/Chap04.html#proposition-how-multiplication-and-addition-of-reals-affects-variance) and [this one](https://logic-teaching.github.io/philstatsbook/Chap04.html#proposition-variance-and-independence)) to find the expectation and variance of $Z$. \n",
    "\n",
    "\n",
    "Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
